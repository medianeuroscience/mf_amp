{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the CSVs\n",
    "\n",
    "words = pd.read_csv(\"condition_files/words4exp.csv\")\n",
    "symbols = pd.read_csv(\"condition_files/symbols.csv\")\n",
    "memtask_words = pd.read_csv(\"condition_files/mem_task_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating word lists\n",
    "\n",
    "unique_cats = {k:None for k in words.category.unique()} \n",
    "\n",
    "for k,v in unique_cats.items():\n",
    "    unique_cats[k] = list(words[words.category == k].index.values)\n",
    "\n",
    "full_amp_words = {k:None for k in unique_cats.keys() if k != \"neutral\"} \n",
    "full_ldt_words = {k:None for k in unique_cats.keys()} \n",
    "\n",
    "for k,v in unique_cats.items():\n",
    "    if \".\" in str(k):\n",
    "        full_amp_words[k] = random.sample(unique_cats[k],7)\n",
    "        full_ldt_words[k] = [x for x in unique_cats[k] if x not in full_amp_words[k]]\n",
    "    if k == \"nonword\":\n",
    "        full_amp_words[k] = random.sample(unique_cats[k],10)\n",
    "        full_ldt_words[k] = [x for x in unique_cats[k] if x not in full_amp_words[k]]\n",
    "    if k ==\"control\":\n",
    "        full_amp_words[k] = unique_cats[k]\n",
    "    if k == \"neutral\":\n",
    "        full_ldt_words[k] = unique_cats[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_primes = [] \n",
    "amp_symbols = range(0,82) \n",
    "\n",
    "for k,v in full_amp_words.items():     \n",
    "    for i in v:\n",
    "        amp_primes.append(i)\n",
    "\n",
    "# Pulling the words, correct answers, and categories for all of the indices for our moral words plus our ten nonword controls \n",
    "\n",
    "AMP_words = words.loc[amp_primes].words.values \n",
    "AMP_corr_ans = words.loc[amp_primes].correct_amp.values \n",
    "AMP_category = words.loc[amp_primes].category.values\n",
    "AMP_masks = words.loc[amp_primes].masks.values\n",
    "\n",
    "#pulling the nonwords and masks for our targets that weren't selected to be included in the prime \n",
    "\n",
    "AMP_symbols = symbols.loc[amp_symbols].symbol.values\n",
    "\n",
    "# df1 is the words that will be used as primes and their associated categories and correct answers  \n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "    {'words': AMP_words.tolist(),\n",
    "    'corr_ans': AMP_corr_ans.tolist(),\n",
    "    'category': AMP_category.tolist(),\n",
    "    'masks': AMP_masks.tolist()\n",
    "    })\n",
    "\n",
    "# df2 is the nonwords that will be used as targets and their associated masks  \n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {'symbols': AMP_symbols.tolist()\n",
    "    })  \n",
    "\n",
    "# Shuffling the words once and then generating four   \n",
    "\n",
    "primes_rep1 = df1.sample(frac=1).reset_index(drop=True) \n",
    "targets_rep1 = df2.sample(frac=1).reset_index(drop=True)  \n",
    "primes_rep2 = df1.sample(frac=1).reset_index(drop=True) \n",
    "targets_rep2 = df2.sample(frac=1).reset_index(drop=True)  \n",
    "primes_rep3 = df1.sample(frac=1).reset_index(drop=True) \n",
    "targets_rep3 = df2.sample(frac=1).reset_index(drop=True)  \n",
    "primes_rep4 = df1.sample(frac=1).reset_index(drop=True) \n",
    "targets_rep4 = df2.sample(frac=1).reset_index(drop=True)  \n",
    "\n",
    "# Concatenating all of the primes and targets and writing them to condition files.\n",
    "\n",
    "rep1 = pd.concat([primes_rep1,targets_rep1], axis = 1)\n",
    "rep1.to_csv(\"condition_files/AMP_rep1.csv\")\n",
    "\n",
    "rep2 = pd.concat([primes_rep2,targets_rep2], axis = 1)\n",
    "rep2.to_csv(\"condition_files/AMP_rep2.csv\")\n",
    "\n",
    "rep3 = pd.concat([primes_rep3,targets_rep3], axis = 1)\n",
    "rep3.to_csv(\"condition_files/AMP_rep3.csv\")\n",
    "\n",
    "rep4 = pd.concat([primes_rep4,targets_rep4], axis = 1)\n",
    "rep4.to_csv(\"condition_files/AMP_rep4.csv\") \n",
    "\n",
    "# Concatenating all of the reps horizontally  \n",
    "\n",
    "df_full = pd.concat([rep1,rep2,rep3,rep4], axis = 0)\n",
    "\n",
    "# Writing AMP conditions to CSV\n",
    "\n",
    "df_full.reset_index(inplace=True, drop=True)\n",
    "df_full.to_csv(\"condition_files/AMP_conditions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating LDT word list\n",
    "\n",
    "ldt_wordlist = [] \n",
    "\n",
    "for k,v in full_ldt_words.items():\n",
    "    if k != \"control\":\n",
    "        for i in v:\n",
    "            ldt_wordlist.append(i)\n",
    "\n",
    "# Pulling the words, correct answers, categories, & masks for all of the indices for our words \n",
    "\n",
    "LDT_words = words.loc[ldt_wordlist].words.values \n",
    "LDT_corr = words.loc[ldt_wordlist].correct_ldt.values \n",
    "LDT_category = words.loc[ldt_wordlist].category.values \n",
    "LDT_masklist = words.loc[ldt_wordlist].masks.values\n",
    "\n",
    "df_ldt = pd.DataFrame(\n",
    "    {'words': LDT_words.tolist(),\n",
    "    'corr_ans': LDT_corr.tolist(),\n",
    "    'category': LDT_category.tolist(),\n",
    "    'mask': LDT_masklist.tolist()     })\n",
    "\n",
    "df_ldt.to_csv(\"condition_files/LDT_conditions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the list for the memory task\n",
    "\n",
    "memtask_wordlist = memtask_words.words.values\n",
    "memtask_cats = memtask_words.category.values\n",
    "seen = pd.DataFrame(\n",
    "    {'words': AMP_words.tolist(),\n",
    "     'corr_ans': ['right'] * 82,\n",
    "     'category': AMP_category.tolist()\n",
    "    })\n",
    "\n",
    "unseen = pd.DataFrame(\n",
    "    {'words': memtask_wordlist.tolist(),\n",
    "     'corr_ans': ['left'] * 50,\n",
    "     'category': memtask_cats.tolist()\n",
    "    })\n",
    "\n",
    "seen_selection = seen.sample(n=50)\n",
    "memtask_final = pd.concat([seen_selection,unseen], axis = 0)\n",
    "memtask_final = memtask_final.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "memtask_final.to_csv(\"condition_files/memtask_conditions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
